# -*- coding: utf-8 -*-
"""alexnet_practice

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qsay5Ea-z-mBGyTDhzVveNBcsRA7-YJh
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms

# --------------------------
# 1. Setup
# --------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

# --------------------------
# 2. Data pipeline
# --------------------------
# upscale cifar10 images
transform_train = transforms.Compose([
    transforms.Resize(224),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

transform_test = transforms.Compose([
    transforms.Resize(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform_train)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,
                                          shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform_test)
testloader = torch.utils.data.DataLoader(testset, batch_size=64,
                                         shuffle=False, num_workers=2)

# --------------------------
# 3. Model
# --------------------------
model = alexnet(num_classes=10).to(device)  # cifar10 has 10 classes

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)

# --------------------------
# 4. Training loop
# --------------------------
num_epochs = 10
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for i, (inputs, targets) in enumerate(trainloader):
        inputs, targets = inputs.to(device), targets.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss/len(trainloader):.4f}")

# --------------------------
# 5. Evaluation
# --------------------------
model.eval()
correct, total = 0, 0
with torch.no_grad():
    for inputs, targets in testloader:
        inputs, targets = inputs.to(device), targets.to(device)
        outputs = model(inputs)
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()

print(f"Test Accuracy: {100. * correct / total:.2f}%")

import matplotlib.pyplot as plt
import numpy as np
import torchvision

# helper to unnormalize for plotting
def imshow(img):
    img = img.cpu().numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    img = std * img + mean
    img = np.clip(img, 0, 1)
    plt.imshow(img)
    plt.axis('off')
    plt.show()

# cifar10 class names
classes = ('plane', 'car', 'bird', 'cat', 'deer',
           'dog', 'frog', 'horse', 'ship', 'truck')

# get one batch
dataiter = iter(testloader)
images, labels = next(dataiter)
images, labels = images.to(device), labels.to(device)

# run through model
outputs = model(images)
_, predicted = outputs.max(1)

# show 4 predictions
for i in range(4):
    imshow(images[i])
    print(f"True: {classes[labels[i]]}, Predicted: {classes[predicted[i]]}")

from PIL import Image

from google.colab import drive
drive.mount('/content/drive')

# Example: if your image is in My Drive/images/dog.png
filename = "/content/drive/My Drive/dog.png"


# preprocess the image the same way as CIFAR-10
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # force 224x224 square
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

img = Image.open(filename).convert("RGB")
input_tensor = transform(img).unsqueeze(0).to(device)

# predict
model.eval()
with torch.no_grad():
    outputs = model(input_tensor)
    _, pred = outputs.max(1)

print("Predicted class:", classes[pred])

import matplotlib.pyplot as plt
import numpy as np

# get the first conv layer
first_conv = model.features[0]  # nn.Conv2d(3, 64, 11, stride=4, padding=2)
weights = first_conv.weight.data.clone().cpu()

print("Conv1 weight shape:", weights.shape)

# -----------------------------
# 1. Plot coefficients as heatmaps
# -----------------------------
fig, axes = plt.subplots(8, 8, figsize=(12, 12))
axes = axes.flatten()
for i in range(64):
    # collapse RGB into a single 11x11 heatmap (mean over channels)
    kernel = weights[i].mean(0)
    axes[i].imshow(kernel, cmap="viridis")
    axes[i].axis("off")
plt.suptitle("Conv1 filter coefficients (mean across RGB channels)")
plt.show()

# -----------------------------
# 2. Plot filters as RGB images
# -----------------------------
fig, axes = plt.subplots(8, 8, figsize=(12, 12))
axes = axes.flatten()
for i in range(64):
    # normalize each filter to [0,1] for visualization
    f = weights[i]
    f_min, f_max = f.min(), f.max()
    f = (f - f_min) / (f_max - f_min)
    f = f.permute(1, 2, 0).numpy()  # [H, W, C]
    axes[i].imshow(f)
    axes[i].axis("off")
plt.suptitle("Conv1 filters visualized as RGB")
plt.show()

import torch
import matplotlib.pyplot as plt

# pick image
dataiter = iter(testloader)
images, labels = next(dataiter)
img = images[0].unsqueeze(0).to(device)  # [1, 3, 224, 224]
label = labels[0].item()

print("True label:", classes[label])

# hook fxn to capture activations
activation = {}
def get_activation(name):
    def hook(model, input, output):
        activation[name] = output.detach()
    return hook

# registser hook on conv2
model.features[3].register_forward_hook(get_activation('conv5'))

# Forward pass
model.eval()
with torch.no_grad():
    _ = model(img)

# get conv2 activations
act = activation['conv5'].cpu().squeeze(0)

print("Conv5 activation shape:", act.shape)

# plot feature maps
fig, axes = plt.subplots(6, 8, figsize=(15, 12))
axes = axes.flatten()
for i in range(48):
    axes[i].imshow(act[i], cmap="viridis")
    axes[i].axis("off")
plt.suptitle("Conv5 feature maps for one image")
plt.show()

